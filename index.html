<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>Face Tracking Debug</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: #1a1a2e;
            min-height: 100vh;
            min-height: -webkit-fill-available;
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            color: white;
            overflow: hidden;
        }

        .container {
            position: relative;
            width: 100%;
            max-width: 500px;
            flex: 1;
            display: flex;
            flex-direction: column;
        }

        .mirror-container {
            position: relative;
            width: 100%;
            flex: 1;
            min-height: 300px;
            overflow: hidden;
            background: #000;
        }

        #video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
            -webkit-transform: scaleX(-1);
        }

        #debugCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .controls {
            padding: 12px;
            background: #16213e;
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            justify-content: center;
        }

        .control-btn {
            padding: 10px 16px;
            border: none;
            border-radius: 20px;
            background: #0f3460;
            color: white;
            font-size: 14px;
            cursor: pointer;
            transition: background 0.2s, transform 0.1s;
        }

        .control-btn:active {
            transform: scale(0.95);
        }

        .control-btn.active {
            background: #e94560;
        }

        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        #startBtn {
            background: #e94560;
            font-weight: 600;
        }

        .status {
            padding: 8px;
            text-align: center;
            font-size: 12px;
            color: #888;
            background: #0f0f1a;
        }

        .loading-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.8);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 100;
        }

        .loading-overlay.hidden {
            display: none;
        }

        .spinner {
            width: 40px;
            height: 40px;
            border: 3px solid #333;
            border-top-color: #e94560;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .loading-text {
            margin-top: 12px;
            font-size: 14px;
            color: #888;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="mirror-container">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="debugCanvas"></canvas>
            <div class="loading-overlay" id="loadingOverlay">
                <div class="spinner"></div>
                <div class="loading-text" id="loadingText">Initializing...</div>
            </div>
        </div>

        <div class="controls" id="controls">
            <button class="control-btn" id="startBtn">Start Camera</button>
        </div>

        <div class="status" id="status">Ready - Tap "Start Camera" to begin</div>
    </div>

    <script type="module">
        import { FaceLandmarker, FilesetResolver } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/+esm';

        // ============================================
        // LANDMARK INDICES (MediaPipe 478 landmarks)
        // ============================================

        // Eyes - iris centers
        const LEFT_EYE_CENTER = 468;   // Left iris center
        const RIGHT_EYE_CENTER = 473;  // Right iris center

        // Eye corners
        const LEFT_EYE_INNER = 133;
        const LEFT_EYE_OUTER = 33;
        const RIGHT_EYE_INNER = 362;
        const RIGHT_EYE_OUTER = 263;

        // Mouth landmarks
        const MOUTH_LEFT = 61;
        const MOUTH_RIGHT = 291;
        const UPPER_LIP_TOP = 13;
        const LOWER_LIP_BOTTOM = 14;

        // Face oval (silhouette) - key points
        const FACE_OVAL = [
            10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,
            397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,
            172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109
        ];

        // Ears (approximate - using face contour near ears)
        const LEFT_EAR_TOP = 127;
        const LEFT_EAR_BOTTOM = 234;
        const RIGHT_EAR_TOP = 356;
        const RIGHT_EAR_BOTTOM = 454;

        // ============================================
        // STATE
        // ============================================

        let faceLandmarker = null;
        let video = null;
        let canvas = null;
        let ctx = null;
        let isRunning = false;
        let animationId = null;

        // ============================================
        // INITIALIZATION
        // ============================================

        async function initializeFaceLandmarker() {
            updateStatus('Loading face detection model...');

            const filesetResolver = await FilesetResolver.forVisionTasks(
                'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm'
            );

            faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                    delegate: 'GPU'
                },
                runningMode: 'VIDEO',
                numFaces: 1,
                minFaceDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5,
                outputFaceBlendshapes: false,
                outputFacialTransformationMatrixes: false
            });

            updateStatus('Model loaded - Ready to start');
            document.getElementById('startBtn').disabled = false;
            hideLoading();
        }

        async function startCamera() {
            try {
                updateStatus('Requesting camera access...');
                showLoading('Accessing camera...');

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'user',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    },
                    audio: false
                });

                video = document.getElementById('video');
                video.srcObject = stream;

                await new Promise((resolve) => {
                    video.onloadedmetadata = () => resolve();
                });

                await video.play();

                // Setup canvas
                canvas = document.getElementById('debugCanvas');
                ctx = canvas.getContext('2d');
                resizeCanvas();

                hideLoading();
                isRunning = true;
                document.getElementById('startBtn').textContent = 'Stop Camera';
                document.getElementById('startBtn').classList.add('active');
                updateStatus('Face tracking active');

                detectFaces();

            } catch (error) {
                console.error('Camera error:', error);
                updateStatus('Camera error: ' + error.message);
                hideLoading();
            }
        }

        function stopCamera() {
            isRunning = false;

            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }

            if (video && video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            }

            if (ctx) {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }

            document.getElementById('startBtn').textContent = 'Start Camera';
            document.getElementById('startBtn').classList.remove('active');
            updateStatus('Camera stopped');
        }

        function resizeCanvas() {
            const container = document.querySelector('.mirror-container');
            const rect = container.getBoundingClientRect();
            canvas.width = rect.width;
            canvas.height = rect.height;
        }

        // ============================================
        // FACE DETECTION & DRAWING
        // ============================================

        function detectFaces() {
            if (!isRunning || !faceLandmarker || !video) return;

            const startTime = performance.now();

            try {
                const results = faceLandmarker.detectForVideo(video, startTime);

                // Clear canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (results.faceLandmarks && results.faceLandmarks.length > 0) {
                    const landmarks = results.faceLandmarks[0];
                    drawDebugOverlay(landmarks);
                }
            } catch (error) {
                console.error('Detection error:', error);
            }

            animationId = requestAnimationFrame(detectFaces);
        }

        function drawDebugOverlay(landmarks) {
            const w = canvas.width;
            const h = canvas.height;

            // Helper to convert landmark to mirrored canvas coordinates
            const toCanvas = (idx) => {
                const lm = landmarks[idx];
                return {
                    x: (1 - lm.x) * w,  // Mirror X
                    y: lm.y * h
                };
            };

            // ---- 1. FACE OVAL (thin outline) ----
            ctx.strokeStyle = 'rgba(0, 255, 255, 0.7)';
            ctx.lineWidth = 2;
            ctx.beginPath();

            const firstOval = toCanvas(FACE_OVAL[0]);
            ctx.moveTo(firstOval.x, firstOval.y);

            for (let i = 1; i < FACE_OVAL.length; i++) {
                const pt = toCanvas(FACE_OVAL[i]);
                ctx.lineTo(pt.x, pt.y);
            }
            ctx.closePath();
            ctx.stroke();

            // ---- 2. EYE DOTS (exact positions) ----
            ctx.fillStyle = '#00ff00';

            // Left eye center
            const leftEye = toCanvas(LEFT_EYE_CENTER);
            ctx.beginPath();
            ctx.arc(leftEye.x, leftEye.y, 6, 0, Math.PI * 2);
            ctx.fill();

            // Right eye center
            const rightEye = toCanvas(RIGHT_EYE_CENTER);
            ctx.beginPath();
            ctx.arc(rightEye.x, rightEye.y, 6, 0, Math.PI * 2);
            ctx.fill();

            // Eye corners (smaller dots)
            ctx.fillStyle = '#ffff00';
            [LEFT_EYE_INNER, LEFT_EYE_OUTER, RIGHT_EYE_INNER, RIGHT_EYE_OUTER].forEach(idx => {
                const pt = toCanvas(idx);
                ctx.beginPath();
                ctx.arc(pt.x, pt.y, 3, 0, Math.PI * 2);
                ctx.fill();
            });

            // ---- 3. MOUTH LINE ----
            const mouthLeft = toCanvas(MOUTH_LEFT);
            const mouthRight = toCanvas(MOUTH_RIGHT);
            const upperLip = toCanvas(UPPER_LIP_TOP);
            const lowerLip = toCanvas(LOWER_LIP_BOTTOM);

            // Horizontal line across mouth
            ctx.strokeStyle = '#ff00ff';
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.moveTo(mouthLeft.x, mouthLeft.y);
            ctx.lineTo(mouthRight.x, mouthRight.y);
            ctx.stroke();

            // Mouth corners dots
            ctx.fillStyle = '#ff00ff';
            ctx.beginPath();
            ctx.arc(mouthLeft.x, mouthLeft.y, 4, 0, Math.PI * 2);
            ctx.fill();
            ctx.beginPath();
            ctx.arc(mouthRight.x, mouthRight.y, 4, 0, Math.PI * 2);
            ctx.fill();

            // Upper and lower lip dots
            ctx.fillStyle = '#ff6600';
            ctx.beginPath();
            ctx.arc(upperLip.x, upperLip.y, 4, 0, Math.PI * 2);
            ctx.fill();
            ctx.beginPath();
            ctx.arc(lowerLip.x, lowerLip.y, 4, 0, Math.PI * 2);
            ctx.fill();

            // ---- 4. EAR LINES ----
            ctx.strokeStyle = '#ffff00';
            ctx.lineWidth = 3;

            // Left ear
            const leftEarTop = toCanvas(LEFT_EAR_TOP);
            const leftEarBottom = toCanvas(LEFT_EAR_BOTTOM);
            ctx.beginPath();
            ctx.moveTo(leftEarTop.x, leftEarTop.y);
            ctx.lineTo(leftEarBottom.x, leftEarBottom.y);
            ctx.stroke();

            // Right ear
            const rightEarTop = toCanvas(RIGHT_EAR_TOP);
            const rightEarBottom = toCanvas(RIGHT_EAR_BOTTOM);
            ctx.beginPath();
            ctx.moveTo(rightEarTop.x, rightEarTop.y);
            ctx.lineTo(rightEarBottom.x, rightEarBottom.y);
            ctx.stroke();

            // Ear endpoint dots
            ctx.fillStyle = '#ffff00';
            [leftEarTop, leftEarBottom, rightEarTop, rightEarBottom].forEach(pt => {
                ctx.beginPath();
                ctx.arc(pt.x, pt.y, 4, 0, Math.PI * 2);
                ctx.fill();
            });
        }

        // ============================================
        // UI HELPERS
        // ============================================

        function updateStatus(message) {
            document.getElementById('status').textContent = message;
        }

        function showLoading(text) {
            document.getElementById('loadingText').textContent = text || 'Loading...';
            document.getElementById('loadingOverlay').classList.remove('hidden');
        }

        function hideLoading() {
            document.getElementById('loadingOverlay').classList.add('hidden');
        }

        // ============================================
        // EVENT HANDLERS
        // ============================================

        document.getElementById('startBtn').addEventListener('click', () => {
            if (isRunning) {
                stopCamera();
            } else {
                startCamera();
            }
        });

        window.addEventListener('resize', () => {
            if (canvas) resizeCanvas();
        });

        // ============================================
        // INITIALIZATION
        // ============================================

        window.addEventListener('load', async () => {
            document.getElementById('startBtn').disabled = true;
            showLoading('Loading face detection...');

            try {
                await initializeFaceLandmarker();
            } catch (error) {
                console.error('Initialization error:', error);
                updateStatus('Error loading: ' + error.message);
                hideLoading();
            }
        });
    </script>
</body>
</html>
